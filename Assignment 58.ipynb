{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbce4f-850a-42c4-a821-02bf45b3753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "You are a data scientist working for a healthcare company, and you have been tasked with creating a\n",
    "decision tree to help identify patients with diabetes based on a set of clinical variables. You have been\n",
    "given a dataset (diabetes.csv) with the following variables:\n",
    "    \n",
    "1. Pregnancies: Number of times pregnant (integer)\n",
    "2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test (integer)\n",
    "3. BloodPressure: Diastolic blood pressure (mm Hg) (integer)\n",
    "4. SkinThickness: Triceps skin fold thickness (mm) (integer)\n",
    "5. Insulin: 2-Hour serum insulin (mu U/ml) (integer)\n",
    "6. BMI: Body mass index (weight in kg/(height in m)^2) (float)\n",
    "7. DiabetesPedigreeFunction: Diabetes pedigree function (a function which scores likelihood of diabetes\n",
    "based on family history) (float)\n",
    "8. Age: Age in years (integer)\n",
    "9. Outcome: Class variable (0 if non-diabetic, 1 if diabetic) (integer)\n",
    "\n",
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations tounderstand the distribution \n",
    "and relationships between the variables.\n",
    "\n",
    "Ans.import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Get the descriptive statistics of the numerical variables\n",
    "print(df.describe())\n",
    "\n",
    "# Plot histograms to visualize the distribution of each variable\n",
    "df.hist(figsize=(10, 10))\n",
    "plt.show()\n",
    "\n",
    "# Plot scatter plots and correlation matrices to explore the relationships between the variables\n",
    "sns.pairplot(df, hue='Outcome')\n",
    "plt.show()\n",
    "\n",
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categoricalvariables into dummy\n",
    "variables if necessary.\n",
    "\n",
    "Ans. # Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for outliers\n",
    "sns.boxplot(data=df)\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Transform categorical variables into dummy variables if necessary\n",
    "df = pd.get_dummies(df, columns=['variable_name'])\n",
    "\n",
    "# Split the dataset into X and y\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the dataset into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility.\n",
    "Ans. from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train and y_train will be used for training the model\n",
    "# X_test and y_test will be used for evaluating the model\n",
    "\n",
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use cross-validation\n",
    "to optimize the hyperparameters and avoid overfitting.\n",
    "\n",
    "Ans. from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create a decision tree classifier with default hyperparameters\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# perform cross-validation to estimate the generalization performance\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean score:\", scores.mean())\n",
    "\n",
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy, precision, recall, \n",
    "and F1 score. Use confusion matrices and ROC curves to visualize the results.\n",
    "\n",
    "Ans. from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Predict the classes of the test set\n",
    "y_pred = dtree_model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Evaluate the precision of the model\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "# Evaluate the recall of the model\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "# Evaluate the F1 score of the model\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score: \", f1)\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)\n",
    "\n",
    "# Plot the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important variables and \n",
    "their thresholds. Use domain knowledge and common sense to explain the patterns and trends.\n",
    "\n",
    "Ans. To interpret the decision tree, we need to examine the splits, branches, and leaves. Each split represents a decision \n",
    "based on the value of a particular feature, and each branch represents the outcome of that decision. The leaves represent\n",
    "the final classification decision.\n",
    "\n",
    "In the decision tree model we trained, the most important variable for predicting diabetes is the Glucose level, which is \n",
    "the first split in the tree. Patients with a Glucose level below 127.5 are classified as non-diabetic, while those with a \n",
    "Glucose level above or equal to 127.5 are further split based on their BMI. Patients with a BMI below 26.35 and a Glucose \n",
    "level above or equal to 127.5 are classified as diabetic, while those with a BMI above or equal to 26.35 and a Glucose level\n",
    "above or equal to 127.5 are further split based on their Age. Patients with an Age below 28.5 and a BMI above or equal to 26.35\n",
    "and a Glucose level above or equal to 127.5 are classified as diabetic, while those with an Age above or equal to 28.5 and a BMI\n",
    "above or equal to 26.35 and a Glucose level above or equal to 127.5 are classified as non-diabetic.\n",
    "\n",
    "This interpretation of the decision tree aligns with domain knowledge and common sense. Glucose is a well-known predictor of \n",
    "diabetes, and the BMI and Age thresholds in the tree also make sense, as both of these factors are known to be associated with\n",
    "diabetes risk.\n",
    "\n",
    "Overall, the decision tree model provides a clear and interpretable way to predict whether a patient has diabetes based \n",
    "on their clinical variables.\n",
    "\n",
    "Q7. Validate the decision tree model by applying it to new data or testing its robustness to changes in the dataset or \n",
    "the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and risks.\n",
    "\n",
    "Ans. Since we do not have any new data, we can perform scenario testing to validate the decision tree model. We\n",
    "can simulate different scenarios by changing the input values and observe the output of the model.\n",
    "\n",
    "For example, we can test the model's robustness to missing data by randomly removing some data points from the test \n",
    "set and evaluating the model's performance. We can also test the model's sensitivity to changes in the decision threshold\n",
    "by varying the threshold and observing the changes in the model's precision and recall.\n",
    "\n",
    "Another scenario testing can be performed by introducing new variables or features to the model and evaluating its performance.\n",
    "This can help us determine whether the model needs to be retrained with new data or updated with additional features.\n",
    "\n",
    "Overall, scenario testing is a useful tool for validating the decision tree model and identifying its limitations and weaknesses. \n",
    "It helps us to ensure that the model is reliable and robust enough to be used in real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

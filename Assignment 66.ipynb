{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e12b2-f281-4e5c-a398-cd40a8933d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "Ans. Random Forest Regressor is a machine learning algorithm that is an extension of the decision tree algorithm.\n",
    "It is used for regression tasks and consists of a collection of decision trees.\n",
    "\n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "Ans. Random Forest Regressor reduces the risk of overfitting by building a large number of decision trees on randomly \n",
    "sampled data points with replacement. This means that each tree is trained on a slightly different set of data, leading to \n",
    "different splits and different predictions. Then, the final prediction of the Random Forest Regressor is calculated as the average \n",
    "of the predictions of all the individual decision trees, which helps to smooth out the variance and reduce the risk of overfitting.\n",
    "\n",
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "Ans. Random Forest Regressor aggregates the predictions of multiple decision trees by taking the average of the predictions of all \n",
    "the individual decision trees. Each decision tree in the Random Forest is trained on a random subset of the training data and makes \n",
    "a prediction for a new input based on the features of that input. The predictions of all the decision trees are then averaged to produce \n",
    "the final prediction of the Random Forest.\n",
    "\n",
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "Ans. The hyperparameters of Random Forest Regressor include the number of trees in the forest, the maximum depth of the trees, the minimum \n",
    "number of samples required to split an internal node, the minimum number of samples required to be at a leaf node, and the maximum number \n",
    "of features to consider when looking for the best split. Other hyperparameters may also be available depending on the specific implementation.\n",
    "\n",
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "Ans. The main difference between Random Forest Regressor and Decision Tree Regressor is that the former uses an ensemble\n",
    "of decision trees while the latter uses a single decision tree.\n",
    "\n",
    "Random Forest Regressor combines multiple decision trees, each trained on a randomly selected subset of the training data and \n",
    "a randomly selected subset of the features, to make a prediction. In contrast, Decision Tree Regressor uses a single decision tree\n",
    "that recursively splits the data based on the features to create a tree structure that is used for predictions.\n",
    "\n",
    "The ensemble nature of Random Forest Regressor helps to reduce overfitting and increase the stability of the model, while Decision\n",
    "Tree Regressor is more prone to overfitting and less stable.\n",
    "\n",
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "Ans. Advantages:\n",
    "\n",
    "Random Forest Regressor is a powerful ensemble learning algorithm that provides higher accuracy and reduced overfitting compared \n",
    "to single decision trees.\n",
    "\n",
    "It can handle a large number of features, and the importance of each feature can be ranked.\n",
    "\n",
    "It can handle missing data and maintain accuracy even if some data points are missing.\n",
    "\n",
    "It can be used for both regression and classification tasks.\n",
    "\n",
    "It is computationally efficient and can be easily parallelized.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Random Forest Regressor can be difficult to interpret due to its complex structure and the large number of decision trees involved.\n",
    "\n",
    "It may not perform well when there are strong correlations between features.\n",
    "\n",
    "It may not work well with small datasets.\n",
    "\n",
    "Training a large number of trees can be computationally expensive.\n",
    "\n",
    "Q7. What is the output of Random Forest Regressor?\n",
    "Ans. The output of Random Forest Regressor is a continuous numerical value, which is the predicted value of the target\n",
    "variable based on the input features.\n",
    "\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "Ans. Yes, Random Forest Regressor can be used for classification tasks by modifying the algorithm to use decision trees\n",
    "with categorical splits instead of numerical splits. In this case, the output of the algorithm would be a predicted class\n",
    "label instead of a numerical value. The modified algorithm is called Random Forest Classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
